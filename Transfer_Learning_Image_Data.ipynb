{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOlc0Srl3hLYZoWTPs5YmXB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vibhuverma17/AUTOML/blob/main/Transfer_Learning_Image_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQCL_MR4IaGx"
      },
      "outputs": [],
      "source": [
        "# TRANSFER LEARNING PROBLEM TARGET NEEDS TO BE VERY SIMILAR\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "id": "bWeGCeiyIzvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "title: \"Transfer Learning with Rock Paper Scissors Dataset\"\n",
        "output: html_document\n",
        "---\n",
        "\n",
        "## Overview\n",
        "\n",
        "In this document, we will apply **transfer learning** to classify images of rock, paper, and scissors using a pre-trained model, **MobileNetV2**. Transfer learning allows us to take advantage of a model that has already learned from a large dataset and apply that knowledge to a smaller, related dataset.\n",
        "\n",
        "## Steps\n",
        "\n",
        "### 1. Load the Dataset\n",
        "\n",
        "We load the **rock_paper_scissors** dataset from TensorFlow Datasets (TFDS). This dataset contains images labeled as rock, paper, or scissors. We split the data into training and testing sets.\n",
        "\n",
        "### 2. Preprocess the Images\n",
        "\n",
        "Before using the images in the model, we resize them to a size that matches what the pre-trained MobileNetV2 model expects (224x224 pixels). We also apply specific preprocessing steps to adjust the images for MobileNetV2.\n",
        "\n",
        "### 3. Optimize the Data Pipeline\n",
        "\n",
        "To make training faster and more efficient, we:\n",
        "- **Cache** the processed images so they don’t need to be reloaded in each epoch.\n",
        "- **Batch** the images into groups of 32, which allows the model to process them together.\n",
        "- **Prefetch** the next batch while the model is processing the current one, reducing downtime during training.\n",
        "\n",
        "### 4. Load a Pre-Trained Model\n",
        "\n",
        "We use **MobileNetV2**, a model that has already been trained on a large dataset (ImageNet). This allows us to leverage the knowledge the model has learned, such as recognizing general patterns in images. We remove the final layer of MobileNetV2, as we will add our own for the classification task.\n",
        "\n",
        "### 5. Build the Model\n",
        "\n",
        "We add a **GlobalAveragePooling2D** layer to reduce the model’s output dimensions and a **Dense** layer with 3 units (one for each class: rock, paper, and scissors). The **softmax** activation function ensures the model outputs probabilities for each class.\n",
        "\n",
        "### 6. Compile and Train the Model\n",
        "\n",
        "We compile the model with the **Adam optimizer**, use the **sparse categorical cross-entropy loss** (because this is a multi-class classification problem), and track **accuracy** as a metric. Then, we train the model on the training dataset.\n",
        "\n",
        "### 7. Fine-Tuning\n",
        "\n",
        "After training the new layers, we unfreeze some layers of the pre-trained MobileNetV2 and allow them to adjust to the specific task of classifying rock, paper, and scissors. We then train the model again with a smaller learning rate to fine-tune it."
      ],
      "metadata": {
        "id": "z9KXNX4LclH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Load the dataset\n",
        "datasets, info = tfds.load(name='rock_paper_scissors', with_info=True, as_supervised=True, split=['train', 'test'])\n",
        "train_ds, test_ds = datasets\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess(image, label):\n",
        "    image = tf.image.resize(image, (224, 224))  # Resize images to match the input size of MobileNetV2\n",
        "    image = tf.keras.applications.mobilenet_v2.preprocess_input(image)  # Preprocessing for MobileNetV2\n",
        "    return image, label\n",
        "\n",
        "# Split the train dataset into training and validation datasets (80% train, 20% validation)\n",
        "val_size = int(0.2 * info.splits['train'].num_examples)  # 20% for validation\n",
        "train_ds, val_ds = train_ds.take(info.splits['train'].num_examples - val_size), train_ds.skip(info.splits['train'].num_examples - val_size)\n",
        "\n",
        "# Apply preprocessing with batch size and caching to training and validation sets\n",
        "train_ds = (train_ds\n",
        "            .map(preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)  # Preprocessing\n",
        "            .cache()  # Caching the data to avoid recomputing\n",
        "            .batch(32)  # Set batch size\n",
        "            .prefetch(tf.data.experimental.AUTOTUNE))  # Prefetch for better performance\n",
        "\n",
        "val_ds = (val_ds\n",
        "          .map(preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)  # Preprocessing\n",
        "          .cache()  # Caching the data\n",
        "          .batch(32)  # Set batch size\n",
        "          .prefetch(tf.data.experimental.AUTOTUNE))  # Prefetch\n",
        "\n",
        "test_ds = (test_ds\n",
        "           .map(preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)  # Preprocessing\n",
        "           .cache()  # Caching the data\n",
        "           .batch(32)  # Set batch size\n",
        "           .prefetch(tf.data.experimental.AUTOTUNE))  # Prefetch"
      ],
      "metadata": {
        "id": "-SN2MOVEI2I_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a pre-trained MobileNetV2 model without the top (fully connected) layer\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
        "\n",
        "# Freeze the entire base model to prevent its layers from being trained\n",
        "base_model.trainable = False\n",
        "\n",
        "# Build the model by adding a classification head on top of the pre-trained model\n",
        "model = tf.keras.Sequential([\n",
        "    base_model,  # Base pre-trained model\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')  # Final classification layer for 3 classes\n",
        "])\n",
        "\n",
        "# Compile the model (only the new classification head will be trained)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "class CollectStatsCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self):\n",
        "        self.batch_losses = []\n",
        "        self.batch_accuracies = []\n",
        "\n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        self.batch_losses.append(logs['loss'])\n",
        "        self.batch_accuracies.append(logs['accuracy'])\n",
        "\n",
        "# Create the callback instance\n",
        "collect_stats_callback = CollectStatsCallback()\n",
        "\n",
        "# Train the model (only the classification head will be trained, base model is frozen)\n",
        "model.fit(train_ds, epochs=2, validation_data=val_ds,callbacks=[collect_stats_callback])"
      ],
      "metadata": {
        "id": "2lHqjZTaboUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot batch loss\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(collect_stats_callback.batch_losses, label='Batch Loss')\n",
        "plt.title('Batch Loss During Training')\n",
        "plt.xlabel('Batch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plot batch accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(collect_stats_callback.batch_accuracies, label='Batch Accuracy')\n",
        "plt.title('Batch Accuracy During Training')\n",
        "plt.xlabel('Batch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Show the plots\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kYq7Pm5cgSIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(test_ds)\n",
        "\n",
        "# Print the results\n",
        "print(f'Test Loss: {test_loss:.4f}')\n",
        "print(f'Test Accuracy: {test_accuracy:.4f}')"
      ],
      "metadata": {
        "id": "tY-nozq6bovo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predictions and true labels from the test dataset\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for image, label in test_ds:\n",
        "    # Get the true labels\n",
        "    y_true.append(label.numpy())\n",
        "\n",
        "    # Get the predicted labels\n",
        "    predictions = model.predict(image)\n",
        "    predicted_labels = np.argmax(predictions, axis=1)\n",
        "    y_pred.append(predicted_labels)\n",
        "\n",
        "# Convert lists to arrays\n",
        "y_true = np.concatenate(y_true)\n",
        "y_pred = np.concatenate(y_pred)\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Rock', 'Paper', 'Scissors'], yticklabels=['Rock', 'Paper', 'Scissors'])\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fnKxTzu_eHbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## WE CAN DO QUANTIZATION OR TF LITE TO MAKE THIS EVEN LIGHTER\n",
        "# QUANTIZATION CAN BE DONE SURING TRAINING OR POST MODEL"
      ],
      "metadata": {
        "id": "7lH0ptdwfuws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_Y-3g9GAf9x7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}